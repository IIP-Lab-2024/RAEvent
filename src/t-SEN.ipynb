{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlpc/miniconda3/envs/LED/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from model.model.personalized_bert import EventBertModel\n",
    "from model.model.PairwiseLecardPLM1 import PairwisePLM1\n",
    "from formatter.PairwiseFormatter1 import PairwiseFormatter\n",
    "from config_parser import create_config\n",
    "from tools.init_tool1 import init_formatter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# plm_path = \"/home/pub/fan/SCR/Pretrain_model/bert_base_chinese\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(plm_path)\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "using EDBERT (Event Detection BERT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /hhd2/fan/SCR/Pretrain_model/bert_base_chinese were not used when initializing EventBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing EventBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EventBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EventBertModel were not initialized from the model checkpoint at /hhd2/fan/SCR/Pretrain_model/bert_base_chinese and are newly initialized: ['bert.embeddings.event_type_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/nlpc/miniconda3/envs/LED/lib/python3.8/site-packages/transformers/modeling_utils.py:713: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "{'inputx': tensor([[  101,  3125,  2692,   839,  2154,  5389,  8138,  2399,   129,  3299,\n",
      "          6629,  6158,  1440,   782,  7357,  2456,  1092,   680,  1453,  3378,\n",
      "          5310,  6399,  1400,  2458,  1993,   769,  2518,  8024,  2400,   680,\n",
      "          1453,  3378,  4638,  2207,  1992,  1987,  1155,  3378,  4508,  4225,\n",
      "          2634,   511,  8127,  2399,  8108,  3299,  8128,  3189,  3241,  8024,\n",
      "          1155,  3378,  4508,  6913,  6435,  1453,  3378,  5635,  3736,  7346,\n",
      "          2356,  3378,  3378,  7252,  3378,  3378,   100,  1548,  3625,  8024,\n",
      "          6158,  1440,   782,  7357,  2456,  1092,   510,  1155,  3378,  4508,\n",
      "          4638,   675,  1923,  3330,  3378,  1469,  3301,  1351,  5918,  3378,\n",
      "           510,  4374,  3378,  1044,  1400,  3341,  1168,   677,  6835,   102,\n",
      "          2528,  8024,  1587,  8024,  3719,  8024,   510,  8024,  2528,  8024,\n",
      "          4195,  8024,  3125,  8024,  2692,  8024,   839,  8024,  2154,  8024,\n",
      "           671,  8024,  3428,  6629,  6401,  2900,  2971,  8024,  8127,  2399,\n",
      "          8110,  3299,   122,  3189,  3241,  8024,  6158,  1440,   782,  2528,\n",
      "          1587,  3719,   510,  2528,  4195,  1469,  4374,  3378,  1762,  1336,\n",
      "          7305,  2356,  2590,  3209,  1277,  5905,  7950,  6983,  1416, 12566,\n",
      "          1259,  1334,  1600,  6983,   511,  3613,  3189,  1119,  3247,   125,\n",
      "          3198,  6387,  8024,  6158,  1440,   782,  2528,  1587,  3719,  1728,\n",
      "           679,  4007,  6421,  6983,  1416,  1259,  1334,  4638,  3302,  1218,\n",
      "          8024,  1762,  5310,  2362,  3198,   680,  3302,  1218,  1447,  1350,\n",
      "          1168,  1259,  1334,  6444,  1905,  4638,  6158,  2154,   782,  7357,\n",
      "          3378,   124,  8020,  4511,  8024,  3649,  2399,  8114,  2259,  8024,\n",
      "          6983,  1416,   712,  5052,  8021,  1355,  4495,   751,  2809,  8024,\n",
      "          6158,   800,   782,  1214,  2458,   511,  1400,  6158,  1440,   782,\n",
      "          2528,  1587,  3719,   510,  2528,  4195,  5023,   782,  4895,  2458,\n",
      "          1259,  1334,  6624,  1168,  6983,  1416,  7305,  1366,  8024,  2496,\n",
      "          6158,  1440,   782,  2528,  1587,  3719,  4692,  1168,  6158,  2154,\n",
      "           782,  7357,  3378,   124,  4991,  1762,  7716,  6662,   704,  7313,\n",
      "          8024,  1315,  2914,  5564,  6158,  1440,   782,  2528,  4195,  4638,\n",
      "          2861,  1214,  8024,  1103,  1403,  1184,   680,  6158,  2154,   782,\n",
      "          7357,  3378,   124,   757,  3666,  8024,  2400,  2898,  7390,  6716,\n",
      "          3025,  2372,  4638,  2835,  1363,  1143,  2927,  1173,  6158,  2154,\n",
      "           782,  7357,  3378,   124,  4638,  5592,  6956,   510,  5520,  6956,\n",
      "           510,  5597,  6956,  5023,  6956,   855,  8024,  5636,  6158,  2154,\n",
      "           782,  7357,  3378,   124,  1358,   839,  3837,  6117,   511,  3309,\n",
      "          7313,  8024,  6158,  1440,   782,  2528,  4195,  1346,   680,  1071,\n",
      "           704,  2400,  6677,  6684,   510,  3666,  2802,  6158,  2154,   782,\n",
      "          7357,  3378,   124,   511,  6158,  2154,   782,  7357,  3378,   124,\n",
      "          5307,  6843,  1278,  2843,  3131,  3187,  3126,  3647,   767,   511,\n",
      "          5307,  3791,  1278,  7063,  2137,  8024,  6158,  2154,   782,  7357,\n",
      "          3378,   124,  5143,  1728,  6716,   860,  1914,  1905,  6158,  1296,\n",
      "          1145,  7229,  1690,  2927,  1173,  5636,  1381,  5511,   510,  5517,\n",
      "          5499,   510,  5499,  5143,  5606,  6117,  5052,  5023,  4788,  6162,\n",
      "          6863,  2768,  1920,  1139,  6117,  5445,  3647,   767,   511,  3428,\n",
      "          1355,  1400,  8024,  6158,  1440,   782,  2528,  1587,  3719,   510,\n",
      "          2528,  4195,  6845,  4895,  4385,  1767,   511,  6158,  1440,   782,\n",
      "          2528,  1587,  3719,  1762,  6845,  6651,  3198,  8024,  2898,  1143,\n",
      "          2014,  5516,  2400,  1153,   839,  1139,  4909,  6756,  1385,  3322,\n",
      "          5529,  3378,  8020,  5307,  7063,  2137,  5143,  6768,  2544,   839,\n",
      "          8021,   511,  6158,  1440,   782,  2528,  1587,  3719,  1762,   677,\n",
      "          6835,  6983,  1416,  7353,  6818,  6158,  6983,   102,     0,     0,\n",
      "             0,     0]]), 'segment': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0]]), 'mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0]]), 'event': tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,  39,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,  53,  53,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,  14,  14,  15,  14,   0,   0,   0,   0,  41,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  41,  51,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,  16,  64,   0,  68,  68,\n",
      "          68,   0,  68,   0,   0,   0,   0,   0,  64,  64,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0, 103, 103, 103, 103,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,  91,   0,   0,   0,   0,  64,  64,\n",
      "           0,  64,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,  13,   0,  43,  43,   0,   0, 102, 102,   0,   0,  13,\n",
      "           0,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,  68,   0,   0,  64,  64,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0, 103,   0,   0,   0, 103, 103,\n",
      "         103,   0, 102, 102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,  97,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,  97,  97,   0,   0,  68,   0,  67,  67,   0,  64,  64,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,  13,   0,   0, 103,   0, 103,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0]])}\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/hhd2/fan/SCR/SCR-Experiment/utils/extracted_cases.csv')\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "def correct_state_dict(state_dict):\n",
    "    \"\"\"调整状态字典中的键名，以适应当前模型结构\"\"\"\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        # 移除所有不必要的'module.'前缀\n",
    "        new_key = k.replace(\"module.\", \"\")\n",
    "        new_state_dict[new_key] = v\n",
    "    return new_state_dict\n",
    "\n",
    "def load_model(model_path):\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    model = PairwisePLM1()\n",
    "    # 使用修正函数处理状态字典\n",
    "    fixed_state_dict = correct_state_dict(checkpoint['model'])\n",
    "    model.load_state_dict(fixed_state_dict)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 假设你的模型保存路径为\n",
    "model_path = '/hhd2/fan/SCR/output/3.pth'\n",
    "model = load_model(model_path)\n",
    "\n",
    "collate_fn = {}\n",
    "formatter = {}\n",
    "acc_result = None\n",
    "data_path = \"/hhd2/fan/SCR/SCR-Experiment/test.json\"\n",
    "def get_data(task_list, *args, **params):\n",
    "    for task in task_list:\n",
    "        print(task)\n",
    "        return PairwiseFormatter(task, *args, **params).process_single(data_path, \"test\")\n",
    "data = get_data([\"test\"], data_path)\n",
    "print(data)\n",
    "print(data[\"inputx\"].shape)\n",
    "# print(data.type)\n",
    "with torch.no_grad():\n",
    "    logits = model(data, \"valid\", acc_result)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = init_test_dataset()\n",
    "\n",
    "# for step, data in enumerate(test_dataset):\n",
    "#     for key in data.keys():\n",
    "#         if isinstance(data[key], torch.Tensor):\n",
    "#             data[key] = Variable(data[key].cuda())\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(data, \"valid\", acc_result)\n",
    "            \n",
    "        # return model.visual.cpu().numpy().flatten()\n",
    "    # inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "    # input_ids = inputs['input_ids'].to(device)\n",
    "    # attention_mask = inputs['attention_mask'].to(device)\n",
    "    # token_type_ids = inputs['token_type_ids'].to(device)\n",
    "    # event_type_ids = torch.zeros_like(input_ids).to(device)\n",
    "    \n",
    "    # input_ids = input_ids.unsqueeze(0)\n",
    "    # attention_mask = attention_mask.unsqueeze(0)\n",
    "    # token_type_ids = token_type_ids.unsqueeze(0)\n",
    "    # event_type_ids = event_type_ids.unsqueeze(0)\n",
    "    # 进行预测\n",
    "    # with torch.no_grad():\n",
    "    #     logits = model({\"inputx\": input_ids, \"mask\": attention_mask, \"segment\": token_type_ids, \"event\": event_type_ids}, \"valid\", None)\n",
    "        # model.visual\n",
    "    # _, outputs = results(**inputs)\n",
    "    # return model.visual.cpu().numpy().flatten()\n",
    "\n",
    "# 获取所有文本的向量表示\n",
    "# vectors = np.array([get_text_embedding(text) for text in texts])\n",
    "\n",
    "# # 应用t-SNE进行降维\n",
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# X_tsne = tsne.fit_transform(vectors)\n",
    "\n",
    "# # 可视化\n",
    "# def plot_with_labels(X, labels):\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     colors = ['r', 'g', 'b', 'c', 'm', 'y']\n",
    "#     unique_labels = list(set(labels))\n",
    "#     color_map = {label: colors[i % len(colors)] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "#     for label in unique_labels:\n",
    "#         idx = [i for i, l in enumerate(labels) if l == label]\n",
    "#         plt.scatter(X[idx, 0], X[idx, 1], c=color_map[label], label=label, alpha=0.5)\n",
    "    \n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_with_labels(X_tsne, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
